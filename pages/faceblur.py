import streamlit as st
from streamlit_extras.let_it_rain import rain
from ultralytics import YOLO
from ultralytics import solutions
import numpy as np
import cv2
from PIL import Image
import torch
from torchvision import models, transforms
import time
import requests
from io import BytesIO
import os


# Custom navigation
page = st.sidebar.selectbox("Navigate", ["ü¶≥", "üëΩ"])


if page == "ü¶≥":
    st.image("faceblurgif.gif", width=1000)

    MODEL_PATH = "models/faces.pt"
    model = YOLO(MODEL_PATH)

    # Init ObjectBlurrer with your 'yolo12' model
    blurrer = solutions.ObjectBlurrer(
        model=MODEL_PATH,
        blur_ratio=0.15,
        line_width=1,
        classes=[0],  # Assuming class '0' corresponds to faces in your model
    )

    # –ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
    uploaded_files = st.file_uploader(
        "üìÅ –ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π",
        type=["jpg", "jpeg", "png"],
        accept_multiple_files=True,
    )
    image_url = st.text_input("üîó –ò–ª–∏ –≤—Å—Ç–∞–≤—å—Ç–µ URL –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è")

    images_to_process = []

    # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å—Å—ã–ª–∫–∏
    if image_url:
        try:
            response = requests.get(image_url)
            response.raise_for_status()  # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –æ—à–∏–±–∫–∏ HTTP
            image = Image.open(BytesIO(response.content)).convert("RGB")
            images_to_process.append(("URL", image))
        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø–æ —Å—Å—ã–ª–∫–µ: {e}")

    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
    STANDARD_SIZE = (640, 640)  # Set a standard size to resize images to
    STANDARD_CHANNELS = 3  # Ensure all images have 3 channels (BGR)

    if uploaded_files:
        for file in uploaded_files:
            try:
                image = Image.open(file).convert(
                    "RGB"
                )  # Convert to RGB to standardize format
                image = image.resize(STANDARD_SIZE)  # Resize to standard size
                open_cv_image = np.array(image)
                open_cv_image = cv2.cvtColor(open_cv_image, cv2.COLOR_RGB2BGR)

                if open_cv_image.shape[2] != STANDARD_CHANNELS:
                    open_cv_image = cv2.cvtColor(open_cv_image, cv2.COLOR_BGRA2BGR)

                images_to_process.append((file.name, open_cv_image))
            except Exception as e:
                st.warning(f"Failed to process {file.name}: {e}")

    # –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –∏ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
    if images_to_process:
        for name, image in images_to_process:
            st.subheader(f"‚öì {name}")

            # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏–∑ PIL –≤ OpenCV —Ñ–æ—Ä–º–∞—Ç
            open_cv_image = np.array(image)
            open_cv_image = cv2.cvtColor(open_cv_image, cv2.COLOR_RGB2BGR)

            # –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ —Ä–∞–∑–º—ã—Ç–∏—è –ª–∏—Ü —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º ObjectBlurrer
            blurrer = solutions.ObjectBlurrer(
                model=MODEL_PATH,
                blur_ratio=0.15,
                line_width=1,
                classes=[0],
            )

            # –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ —Ä–∞–∑–º—ã—Ç–∏—è –ª–∏—Ü —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º ObjectBlurrer
            results = blurrer(open_cv_image)

            # –ü–æ–ª—É—á–µ–Ω–∏–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            blurred_image = results.plot_im

            # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –æ–±—Ä–∞—Ç–Ω–æ –≤ —Ñ–æ—Ä–º–∞—Ç PIL –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
            blurred_image_pil = Image.fromarray(
                cv2.cvtColor(blurred_image, cv2.COLOR_BGR2RGB)
            )

            # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
            st.image(blurred_image_pil, width=700)

            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ —Å—Å—ã–ª–∫–∏ –Ω–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ
            output_path = f"{name}_face_blurred.jpg"
            blurred_image_pil.save(output_path)
            with open(output_path, "rb") as file:
                st.download_button(
                    label="üì• –°–∫–∞—á–∞—Ç—å —Ä–∞–∑–º—ã—Ç—É—é –∫–∞—Ä—Ç–∏–Ω–∫—É",
                    data=file,
                    file_name=output_path,
                    mime="image/jpeg",
                )


elif page == "üëΩ":
    correct_pass = False

    st.markdown(
        """
        <style>
            /* Change the background color of the entire app */
            .stApp {
                background-color: black !important;
            }

            /* Change the font color for all text */
            body {
                color: green !important;
            }

            /* Optional: Style headers (h1, h2, etc.) */
            h1, h2, h3, h4, h5, h6, div {
                color: limegreen !important; /* Brighter green for headings */
            }

            /* Optional: Style buttons */
            .stButton > button {
                background-color: green !important;
                color: white !important;
                border-radius: 5px;
            }

            /* Optional: Style input widgets */
            .stTextInput > div > div > input,
            .stTextArea > div > div > textarea {
                background-color: white !important;
                color: green !important;
            }
        </style>
    """,
        unsafe_allow_html=True,
    )

    def alien():
        rain(
            emoji="üë®‚Äçüíª",
            font_size=50,
            falling_speed=6,
            animation_length="infinite",
        )

    def clown():
        rain(
            emoji="ü§°",
            font_size=100,
            falling_speed=4,
            animation_length=15,
        )

    st.image("matrixgif.gif", width=1000)

    # Initialize session state variables
    if "show_password_input" not in st.session_state:
        st.session_state.show_password_input = False

    # Function to simulate password validation
    def check_password(password):
        # Replace "your_secure_password" with your actual password
        correct_password = "ValueError"
        return password == correct_password

    # Main app logic

    st.title("ENTER THE MATRIX")

    # Button to trigger password input
    if st.button("–Ø –ì–û–¢–û–í –ö –ü–†–ê–í–î–ï"):
        st.session_state.show_password_input = True

    # Show password input only if the button has been pressed
    if st.session_state.show_password_input:
        password = st.text_input(
            "**–í–í–ï–î–ò –ü–ê–†–û–õ–¨ –î–õ–Ø –ò–ó–ë–†–ê–ù–ù–´–• –ò –í–°–¢–†–ï–¢–¨–°–Ø –° –ò–ó–ë–†–ê–ù–ù–´–ú –õ–ò–¶–û–ú –ö –õ–ò–¶–£**",
            type="password",
        )

        # Check if the user has entered a password
        if password:
            if check_password(password):
                st.success("Access Granted!")
                # Add your protected content here
                st.markdown(
                    "<p style='font-size: 40px;'>üë®‚ÄçüíªWelcome to the Matrix!</p>",
                    unsafe_allow_html=True,
                )
                st.write("This is some secret content.")
                alien()
                correct_pass = True
            else:
                st.error("–¢–´ –ù–ï –î–û–°–¢–û–ò–ù.")
                clown()
                correct_pass = False

    if correct_pass == True:
        MODEL_PATH = "models/faces.pt"
        model = YOLO(MODEL_PATH)

        # Load the mask image
        mask = cv2.imread(
            "tim.png", cv2.IMREAD_UNCHANGED
        )  # Load with alpha channel if present
        if mask is None:
            st.error("The mask image 'tim.png' could not be found or loaded.")
            st.stop()

        # –ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
        uploaded_files = st.file_uploader(
            "üìÅ –ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π",
            type=["jpg", "jpeg", "png"],
            accept_multiple_files=True,
        )
        image_url = st.text_input("üîó –ò–ª–∏ –≤—Å—Ç–∞–≤—å—Ç–µ URL –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è")

        images_to_process = []

        # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å—Å—ã–ª–∫–∏
        if image_url:
            try:
                response = requests.get(image_url)
                response.raise_for_status()  # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –æ—à–∏–±–∫–∏ HTTP
                image = Image.open(BytesIO(response.content)).convert("RGB")
                images_to_process.append(("URL", image))
            except Exception as e:
                st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø–æ —Å—Å—ã–ª–∫–µ: {e}")

        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
        STANDARD_SIZE = (640, 640)  # Set a standard size to resize images to
        STANDARD_CHANNELS = 3  # Ensure all images have 3 channels (BGR)

        images_to_process = []

        if uploaded_files:
            for file in uploaded_files:
                try:
                    image = Image.open(file).convert(
                        "RGB"
                    )  # Convert to RGB to standardize format
                    image = image.resize(STANDARD_SIZE)  # Resize to standard size
                    open_cv_image = np.array(image)
                    open_cv_image = cv2.cvtColor(open_cv_image, cv2.COLOR_RGB2BGR)

                    if open_cv_image.shape[2] != STANDARD_CHANNELS:
                        open_cv_image = cv2.cvtColor(open_cv_image, cv2.COLOR_BGRA2BGR)

                    images_to_process.append((file.name, open_cv_image))
                except Exception as e:
                    st.warning(f"Failed to process {file.name}: {e}")

        # –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –∏ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
        if images_to_process:
            for name, image in images_to_process:
                st.subheader(f"‚öì {name}")

                # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏–∑ PIL –≤ OpenCV —Ñ–æ—Ä–º–∞—Ç
                open_cv_image = np.array(image)
                open_cv_image = cv2.cvtColor(open_cv_image, cv2.COLOR_RGB2BGR)

                # –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Å –ø–æ–º–æ—â—å—é –º–æ–¥–µ–ª–∏ YOLO
                results = model(open_cv_image)[0]

                # –ü–æ–ª—É—á–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–æ–≤ –º–∞—Å–∫–∏
                mask_h, mask_w = mask.shape[:2]

                # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞–∂–¥–æ–π –æ–±–Ω–∞—Ä—É–∂–µ–Ω–Ω–æ–π –æ–±–ª–∞—Å—Ç–∏ (–ª–∏—Ü)
                for box in results.boxes:
                    x1, y1, x2, y2 = map(int, box.xyxy[0].tolist())
                    bbox_w, bbox_h = x2 - x1, y2 - y1

                    # –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ –º–∞—Å–∫–∏ –¥–ª—è —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è —Ä–∞–∑–º–µ—Ä—É –æ–±–Ω–∞—Ä—É–∂–µ–Ω–Ω–æ–π –æ–±–ª–∞—Å—Ç–∏
                    scale_factor = min(bbox_w / mask_w, bbox_h / mask_h) * 2.2
                    new_size = (int(mask_w * scale_factor), int(mask_h * scale_factor))
                    resized_mask = cv2.resize(
                        mask, new_size, interpolation=cv2.INTER_AREA
                    )

                    rm_h, rm_w = resized_mask.shape[:2]
                    center_x, center_y = x1 + bbox_w // 2, y1 + bbox_h // 2
                    top_left_x = center_x - rm_w // 2
                    top_left_y = center_y - rm_h // 2

                    # –ü—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏–µ –≤—ã—Ö–æ–¥–∞ –º–∞—Å–∫–∏ –∑–∞ –ø—Ä–µ–¥–µ–ª—ã –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
                    top_left_x = max(0, top_left_x)
                    top_left_y = max(0, top_left_y)
                    bottom_right_x = min(open_cv_image.shape[1], top_left_x + rm_w)
                    bottom_right_y = min(open_cv_image.shape[0], top_left_y + rm_h)
                    resized_mask = resized_mask[
                        : bottom_right_y - top_left_y, : bottom_right_x - top_left_x
                    ]

                    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∞–ª—å—Ñ–∞-–∫–∞–Ω–∞–ª–∞ (–µ—Å–ª–∏ –æ–Ω —Å—É—â–µ—Å—Ç–≤—É–µ—Ç)
                    if resized_mask.shape[2] == 4:
                        alpha_mask = resized_mask[:, :, 3] / 255.0
                        mask_rgb = resized_mask[:, :, :3]
                    else:
                        alpha_mask = np.ones((rm_h, rm_w))
                        mask_rgb = resized_mask

                    roi = open_cv_image[
                        top_left_y:bottom_right_y, top_left_x:bottom_right_x
                    ]

                    # –ù–∞–ª–æ–∂–µ–Ω–∏–µ –º–∞—Å–∫–∏ –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
                    for c in range(3):  # –î–ª—è –∫–∞–∂–¥–æ–≥–æ –∫–∞–Ω–∞–ª–∞ (B, G, R)
                        roi[:, :, c] = (
                            alpha_mask * mask_rgb[:, :, c]
                            + (1 - alpha_mask) * roi[:, :, c]
                        ).astype(np.uint8)

                    open_cv_image[
                        top_left_y:bottom_right_y, top_left_x:bottom_right_x
                    ] = roi

                # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –æ–±—Ä–∞—Ç–Ω–æ –≤ —Ñ–æ—Ä–º–∞—Ç PIL –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
                output_image = Image.fromarray(
                    cv2.cvtColor(open_cv_image, cv2.COLOR_BGR2RGB)
                )
                st.image(output_image, width=700)

                # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ —Å—Å—ã–ª–∫–∏ –Ω–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ
                output_path = f"{name}_modified.jpg"
                output_image.save(output_path)
                with open(output_path, "rb") as file:
                    st.download_button(
                        label="üì• –°–∫–∞—á–∞—Ç—å –∏–∑–º–µ–Ω—ë–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ",
                        data=file,
                        file_name=output_path,
                        mime="image/jpeg",
                    )
